# BigData
Tutorial sobre ferramentas BigData padrão (apache) - sem comercial

# Hadoop

* 1. HDFS - Sistema de arquivos distribuidos
* 2. YARN - Gerenciamento de Recursos
* 3. MAP REDUCE - Framework para executar operações de **map** e **reduce**

# Spark
* 0. Frameworks para dar suporte ao Spark por debaixo dos panos.
* 1. Processo Master - 
* 2. Processo Worker - 
* 3. API inicial voltada a particionar dados em RDD
* 4. API atual voltada a enxergar os RDDs como sendo DataFrames/Datasets
* 5. Salvando o que está em memória.
* 6. Usando o SQL nisso tudo - Hive.
* 7. Uma estrutura de dados com suporte a dados Espaciais.
* 8. Interagindo com o cluster - submetendo em scala
* 9. Interagindo com o cluster - submetendo em java
* 10. Interagindo com o cluster - submetendo em python
* 11. Interagindo com o cluster - submetendo em R


# o que mais se aproxima de Bancos de Dados
* 1. HBase
* 2. Cassandra
* 3. Neo4j
* 4. MongoDB
* 5. Kafka
* 6. Accumulo

# Ferramentas do ecossistema
* - Pig
* - Hive
* - Sqoop
* - Flume
* - ZooKeeper


